---
title: "E9"
output: html_document
date: "2023-11-16"
---

Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de menor edad del equipo.

```{r}
library(ggplot2)
library(tidyverse)
library(ggpubr)
library(leaps)

```

Seleccionar una muestra de 50 mujeres (si la semilla es un número par) o 50 hombres (si la semilla es impar).
Seleccionar de forma aleatoria ocho posibles variables predictoras.

------------------------------------------------------------------------
1 Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de menor edad del equipo.
Se define la semilla como 7387, ya que es el menor RUN del equipo.

2 Seleccionar una muestra de 50 mujeres (si la semilla es un número par) o 50 hombres (si la semilla es impar).
En nuestro caso se selecciona una muestra de 50 hombres, ya que la semilla es impar.

3 Seleccionar de forma aleatoria ocho posibles variables predictoras.
Para seleccionar las variables predictoras, se leen los datos, luego se filtran los 50 hombres y se eligen 8 variables de forma aleatoria.
------------------------------------------------------------------------
```{r}
set.seed(7387)
datos <- read.csv2("EP09 Datos.csv", header = TRUE, sep = ";")
# Se filtra por la variable gender, donde hombre es igual a 1
datos_filtrados <- datos[datos$Gender == 1,]

# Se eligen 50 hombres de forma aleatoria
datos_muestra <- datos_filtrados[sample(nrow(datos_filtrados), 50), ]

# Se eligen 8 variables de forma aleatoria
datos_muestra_predictoras <- datos_muestra[, sample(ncol(datos_muestra), 8)]
variables_predictoras <- names(datos_muestra_predictoras) # Se guardan los nombres de las variables predictoras
```

------------------------------------------------------------------------
4 Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la variable Peso, justificando bien esta selección.
------------------------------------------------------------------------

4 . 
```{r}
# Se crea una variable datos_muestras_2 que contiene todas las variables que no se eligieron en el punto anterior
datos_muestra_2 <- datos_muestra[, !names(datos_muestra) %in% variables_predictoras]
nombres_variables <- names(datos_muestra_2)

# Se utiliza el metodo de selección hacia adelante para evaluar cual variable predictora es la mejor candidata para el modelo de regresión lineal simple.
# Se crea el modelo vacio
modelo_vacio <- lm(Weight ~ 1, data = datos_muestra_2)
# Se ajusta el modelo completo
completo <- lm(Weight ~ ., data = datos_muestra_2)
print(add1(modelo_vacio, scope = completo))
```
------------------------------------------------------------------------
5 Usando el entorno R, construir un modelo de regresión lineal simple con el predictor seleccionado en el paso anterior.
------------------------------------------------------------------------
5 . 
```{r}
# Se elige la que tenga menor AIC (es decir, Hip.Girth)
modelo <- update(modelo_vacio, . ~ . + Hip.Girth)
```
```{r}
# Se evalua el modelo con AIC
modelo_aic <- AIC(modelo)
print(modelo_aic) # 320.392
```

------------------------------------------------------------------------
6 Usando herramientas para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal simple obtenido en el paso 5.
------------------------------------------------------------------------
6 .
```{r}
# Se agrega la columna Weight al dataframe datos_muestra_predictoras
datos_muestra_predictoras$Weight <- datos_muestra$Weight
# Se agrega a las columnas de variables elegidas la columna Hip.Girth desde los datos_muestra
datos_muestra_predictoras$Hip.Girth <- datos_muestra$Hip.Girth
modelo <- lm(Weight ~ Hip.Girth, data = datos_muestra_predictoras)
# Se crea modelo con todas las variables predictoras elegidas
completo2 <- lm(Weight ~ ., data = datos_muestra_predictoras)
# Se eligen las variables con el ajuste del modelo hacia adelante
adelante <- step(modelo, scope = list(upper = completo2), direction = "forward", trace = 0)

print(summary(adelante))
```

Se puede ver en el modelo hacia adelante que las mejores variables para agregar al modelo (que en este caso se decide agregar solo 3 más) son: Chest.diameter, Elbows.diameter y Navel.Girth. Por loi tanto, se agregan al modelo.

```{r}
modelo <- update(modelo, . ~ . + Chest.diameter + Elbows.diameter + Navel.Girth)
AIC(modelo) # 289.7187
```

```{r}
```

------------------------------------------------------------------------
7 Evaluar los modelos y “arreglarlos” en caso de que tengan algún problema con las condiciones que deben cumplir.
------------------------------------------------------------------------
7 . Se utiliza el código propuesto en Perusall en la lectura 13 para poder identificar valores con sobre influencia.
Primero se obtiene los datos a evaluar y se almacenan en un data frame
```{r}
# Construir una matriz de datos con la respuesta predicha, los residuos y algunas estadísticas para evaluar la influencia de cada observación
resultados <- data.frame(respuesta_predicha = fitted(modelo))
resultados[["residuos_estandarizados"]] <- rstandard(modelo)
resultados[["residuos_estudiantizados"]] <- rstudent(modelo)
resultados[["distancia_Cook"]] <- cooks.distance(modelo)
resultados[["dfbeta"]] <- dfbeta(modelo)
resultados[["dffit"]] <- dffits(modelo)
resultados[["apalancamiento"]] <- hatvalues(modelo)
resultados[["covratio"]] <- covratio(modelo)
```


Se revisan las condiciones sobre los residuos estandarizados que deben de seguir una distribución normal estandar.
```{r}
cat("Identificación de valores atípicos:\n")
# Observaciones con residuos estandarizados fuera del 95% esperado
sospechosos1 <- which(abs(resultados[["residuos_estandarizados"]]) > 1.96)
cat("- Residuos estandarizados fuera del 95% esperado: ", sospechosos1, "\n")
```
Se observa que solo hay 3 datos fuera del 95% quese debería concentrar entre 1.96 y -1.96, por lo que no hay algo que sea significativo para sospechar.


Luego se filtran y ordenan los datos de la distancia de Cook
```{r}
# Observaciones con distancia de Cook mayor a uno
sospechosos2 <- which(resultados[["distancia_Cook"]] > 1)
cat("- Residuos con una distancia de Cook alta: ", sospechosos2, "\n")
```
Se puede dar cuenta que ninguno de los valores de la distancia de Cook es mayor a 1, por lo que no se considera que haya valores atipicos.

Se calcula el valor de apalancamiento medio y se filtran los valores que tengan un valor mayor a este.
```{r}
# Observaciones con apalancamiento mayor igual al doble del apalancamiento promedio
apal_medio <- (ncol(datos_muestra_predictoras) + 1) / nrow(datos_muestra_predictoras)
sospechosos3 <- which(resultados[["apalancamiento"]] > 2 * apal_medio)
cat("- Residuos con apalancamiento fuera de rango: ", sospechosos3, "\n")
```
Resulta que no hay valores que tengan una influencia significativa generando un efecto de apalancamiento

Comprobamos que no haya valores que tengan un DFBeta mayor a 1
```{r}
# Observaciones con DFBeta mayor o igual a 1
sospechosos4 <- which(apply(resultados[["dfbeta"]] >= 1, 1, any))
names(sospechosos4) <- NULL
cat("- Residuos con DFBeta >= 1: ", sospechosos4, "\n")
```
Se encuentran 8 valores que tienen un DFBeta mayor a 1, por lo que se considera que estos valores tienen una influencia significativa en el modelo.

Se calcula el rango de la razón de covarianza y se filtran los valores que esten fuera de este rango
```{r}
# Observaciones con razón de covarianza fuera de rango
inferior <- 1 - 3 * apal_medio
superior <- 1 + 3 * apal_medio
sospechosos5 <- which(resultados[["covratio"]] < inferior | resultados[["covratio"]] > superior)
cat("- Residuos con razón de covarianza fuera de rango: ", sospechosos5, "\n")
```
Solo hay un valor que esta fuera del rango, por lo que no se considera que sea significativo.


Se imprime un resumen de los valores sospechosos
```{r}
# Resumen de valores sospechosos
sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4, sospechosos5)
sospechosos <- sort(unique(sospechosos))

cat("\nResumen de valores sospechosos:\n")
cat("Apalancamiento promedio: ", apal_medio, "\n")
cat("Intervalo razón de covarianza: [", inferior, "; ", superior, "]\n\n", sep = "")

print(round(resultados[sospechosos, c("distancia_Cook", "apalancamiento", "covratio")], 3))
```

Se termina de comprobar las condiciones del modelo y se observa que no hay valores que tengan una influencia significativa en el modelo, por lo que se considera que el modelo esta bien y cumple las condiciones.

8 Evaluar el poder predictivo del modelo en datos no utilizados para construirlo (o utilizando validación cruzada).
```{r}
#Se trabaja con validación cruzada, utilizando la informacion del texto anterior

# Cargar conjunto de datos de entrenamiento y prueba
n <- nrow(datos)
n_entrenamiento <- floor(0.7*n)
muestra <- sample.int(n = n, size = n_entrenamiento, replace = FALSE)
entrenamiento <- datos[muestra, ]
prueba <- datos[-muestra, ]

# Ajustar modelo con el conjunto de entrenamiento
modelo <- lm(Weight ~ Hip.Girth, data = entrenamiento)

# Calcular el error cuadrado promedio para el conjunto de entrenamiento
mse_entrenamiento <- mean(modelo$residuals ** 2)
cat("MSE para el conjunto de entrenamiento:", mse_entrenamiento, "\n")

# Hacer predicciones para el conjunto de prueba
predicciones <- predict(modelo, prueba)

# Calcular el error cuadrado promedio para el conjunto de prueba
error <- prueba[["Weight"]] - predicciones
mse_prueba <- mean(error ** 2)
cat("MSE para el conjunto de prueba:",mse_prueba)
```
